{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP Growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import functools\n",
    "sys.path.append('..')\n",
    "from utils.utils import flatten, is_subset_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/store_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class HT\n",
    "### HT data structure\n",
    "```cpp\n",
    "struct ht {\n",
    "  info: (key, counts),\n",
    "  next: next_addr;\n",
    "}\n",
    "```\n",
    "\n",
    "- The class HT is used to create the header table, which will save the information of frequent item set in desceding order\n",
    "- And, header table also have the duty to store the address of each frequent item and each frequent item also point to next itself item\n",
    "\n",
    "### Function\n",
    "- build_ht : build the header table\n",
    "- find_until_none : this method is to save the instance into the linked-list chain\n",
    "- find_key_in_ht : return the address of desired item(class Node) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HT :\n",
    "    def __init__(self):\n",
    "        self.ht = None\n",
    "    \n",
    "    def build_ht(self, data, min_sup):\n",
    "        if self.ht == None:\n",
    "            self.ht = []\n",
    "        keys, counts = np.unique(flatten(data), return_counts=True)\n",
    "        ht_arr = np.array([(i,j) for i,j in zip(keys, counts)], dtype=[('key', int), ('counts', int)])\n",
    "        rst = np.flip(np.sort(ht_arr, order='counts'))\n",
    "        rst = filter(lambda x: x if x[1]>=min_sup else None, rst)\n",
    "        rst = [ {'info':d, 'next': None}  for d in rst]\n",
    "        self.ht = list(rst)\n",
    "    \n",
    "    def find_until_none(self, key, addr):\n",
    "        for d in self.ht:\n",
    "            if d['info'][0] == key and d['next'] != None:\n",
    "                cur = d['next']\n",
    "                while cur.next_instance != None:\n",
    "                    cur = cur.next_instance\n",
    "                cur.next_instance = addr\n",
    "                return\n",
    "            elif d['info'][0] == key and d['next'] == None:\n",
    "                d['next'] = addr\n",
    "                return\n",
    "        raise \"No wanted key it is wierd\"\n",
    "    \n",
    "    def find_key_in_ht(self, key):\n",
    "        for d in self.ht:\n",
    "            if d['info'][0] == key:\n",
    "                return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Node\n",
    "The node will store the following info\n",
    "- numOfChild : number of children\n",
    "- _key : the key of this object\n",
    "- _count : the number of times the frequent item match\n",
    "- next_instance : store the address of the next same key node\n",
    "- slots : it is a list which contain the tuple, (key, value(address) )\n",
    "- parent : the address of its parent\n",
    "### Functions\n",
    "- insertNode : insert a child node to this node\n",
    "- findWithKey : find the key whether it is of its children\n",
    "- contain_with : return bool value indicate whether the key is its child or not\n",
    "\n",
    "### Special function\n",
    "It is made to operate the node more directly\n",
    "- __add__ : which will add the node as its child and increments its numOfChild\n",
    "- __gt__ : which will return the child given the key and no match item will return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node :\n",
    "    def __init__(self, name):\n",
    "        self.numOfChild = 0\n",
    "        self._key = name\n",
    "        self._count = 0\n",
    "        self.next_instance = None\n",
    "        self.slots = None\n",
    "        self.parent = None\n",
    "\n",
    "    @classmethod\n",
    "    def DFS_tra(self, cls):\n",
    "        if cls.children == None:\n",
    "            return\n",
    "        for nkeys,value in cls.children.items():\n",
    "            print(nkeys, value.count)\n",
    "            Node.DFS_tra(value)\n",
    "        \n",
    "    @classmethod\n",
    "    def DFS_search(self, cls, addr, path, global_path):\n",
    "        if cls.children == None:\n",
    "            return\n",
    "        for nkeys, value in cls.children.items():\n",
    "            path.append(value)\n",
    "            if value == addr:\n",
    "                global_path.append(path.copy())\n",
    "                del path[-1]\n",
    "                return\n",
    "            else:\n",
    "                Node.DFS_search(value, addr, path, global_path)\n",
    "            del path[-1]\n",
    "                \n",
    "    @property\n",
    "    def key(self):\n",
    "        return self._key\n",
    "    \n",
    "    @property\n",
    "    def children(self):\n",
    "        return self.slots\n",
    "    \n",
    "    @property\n",
    "    def count(self):\n",
    "        return self._count\n",
    "    @count.setter\n",
    "    def count(self, addOne):\n",
    "        self._count += addOne\n",
    "    \n",
    "    def insertNode(self, node):\n",
    "        if self.slots == None:\n",
    "            self.slots = {}\n",
    "        self.slots[node.key] = node\n",
    "        node.parent = self\n",
    "    \n",
    "    def findWithKey(self, key):\n",
    "        if self.slots == None:\n",
    "            return None\n",
    "        for nkey,value in self.slots.items():\n",
    "            if nkey == key:\n",
    "                return value\n",
    "        return None\n",
    "\n",
    "    def contain_with(self, key):\n",
    "        if self.slots == None:\n",
    "            return False\n",
    "        for nkey,value in self.slots.items():\n",
    "            if nkey == key:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def generator(self, cur):\n",
    "        if cur == None:\n",
    "            return None\n",
    "        return cur.next_instance\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        self.insertNode(other)\n",
    "        self.numOfChild += 1\n",
    "        other.count = 1\n",
    "        return other\n",
    "\n",
    "    def __gt__(self, other_key):\n",
    "        return self.findWithKey(other_key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "root\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "root = Node('root')\n",
    "root + Node(55)\n",
    "(root > 55) + Node(77)\n",
    "child = (root > 55) > 77\n",
    "print(child.parent.key)\n",
    "print(child.parent.parent.key)\n",
    "c = (root > 55) + Node(56)\n",
    "print(c.parent.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPEstimator(HT)\n",
    "which inherits from class HT so it have the ability to build the header table and  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPEstimator(HT):\n",
    "    ''' @FPEstimator inherented from HT\n",
    "        @pro:\n",
    "            1. data\n",
    "            2. shape\n",
    "            3. l1label\n",
    "            4. Encoder\n",
    "    '''\n",
    "    def __init__(self, df_data):\n",
    "        super().__init__()\n",
    "        self.df_data = df_data\n",
    "        self.dshape = df_data.shape\n",
    "        self.le = LabelEncoder()\n",
    "        self.extract_items(df_data)\n",
    "        self.root = None\n",
    "        self.relations = None\n",
    "        self.fp_n = None\n",
    "        self.fp_n_encoded = None\n",
    "        \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.df_data\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.dshape\n",
    "    \n",
    "    @property\n",
    "    def l1label(self):\n",
    "        return list(zip(self.itemset, self.l1_count))\n",
    "    @property\n",
    "    def Encoder(self):\n",
    "        return self.le     \n",
    "    \n",
    "    def extract_items(self, data):\n",
    "        self.raw_items = []\n",
    "        for index, row in data.iterrows():\n",
    "            row = pd.Series(row).dropna().values\n",
    "            self.raw_items.append(np.array(row).tolist())\n",
    "        self.itemset, self.l1_count = np.unique(flatten(self.raw_items), return_counts=True)\n",
    "        self.le.fit(self.itemset)\n",
    "        self.encoded_data = [ self.le.transform(d) for d in self.raw_items ]\n",
    "    \n",
    "    def order_cmp(self,x,y):\n",
    "        return self.htl.index(x) - self.htl.index(y)\n",
    "    \n",
    "    def build_tree(self, min_sup, print_out=False):\n",
    "        if self.root == None:\n",
    "            self.root = Node('r')\n",
    "        self.build_ht(self.encoded_data, min_sup)\n",
    "        cur = None\n",
    "        self.rearr_data = []\n",
    "        htk = { d['info'][0] for d in self.ht }\n",
    "        self.htl = [ d['info'][0] for d in self.ht ]\n",
    "        for index, row in enumerate(self.encoded_data):\n",
    "            l = list(set(row).intersection(htk))\n",
    "            l = sorted(l,key=functools.cmp_to_key(self.order_cmp))\n",
    "            self.rearr_data.append(l)\n",
    "        for index, row in enumerate(self.rearr_data):\n",
    "            cur = self.root\n",
    "            for d in row:\n",
    "                if print_out:\n",
    "                    print(d, end=' ')\n",
    "                if not cur.contain_with(d):\n",
    "                    cur = cur + Node(d)\n",
    "                    self.find_until_none(d, cur)\n",
    "                else:\n",
    "                    cur = cur.findWithKey(d)\n",
    "                    cur.count = 1\n",
    "        self.min_sup = min_sup\n",
    "        self.relations = None\n",
    "\n",
    "    def combination_with_pattern(self, ls, bit, key, value, global_ls):\n",
    "        if bit:\n",
    "            ls.append((key, value.count))\n",
    "        if value.children == None:\n",
    "            if len(ls) != 0:\n",
    "                global_ls.append(ls.copy())\n",
    "            return\n",
    "        for dkey, dvalue in value.children.items():\n",
    "            self.combination_with_pattern(ls, 0, dkey, dvalue, global_ls)\n",
    "            self.combination_with_pattern(ls, 1, dkey, dvalue, global_ls)\n",
    "            ls.pop()\n",
    "\n",
    "    def gen_list(self, print_cpb=False, print_relation=False):\n",
    "        if self.relations == None:\n",
    "            self.relations = {}\n",
    "        if self.min_sup == None:\n",
    "            print(\"You need to execute build_tree first\")\n",
    "        global_path = []\n",
    "        with tqdm(total = len(self.ht)+1) as pbar:\n",
    "            for i in range(1, len(self.ht) + 1):\n",
    "                global_path = []\n",
    "                global_ls = []\n",
    "                cur = self.ht[-i]['next']\n",
    "                #print(f\"Find {cur.key}  {self.le.inverse_transform([cur.key])[0]}\")\n",
    "                self.relations[cur.key] = global_ls\n",
    "                while cur != None:   \n",
    "                    path = []\n",
    "                    Node.DFS_search(self.root, cur, path, global_path)\n",
    "                    cur = cur.next_instance\n",
    "                if print_cpb:\n",
    "                    for ls in global_path:\n",
    "                        for item in ls:\n",
    "                            print(f\"({item.key} {item.count})\", end=' ')\n",
    "                        print('')\n",
    "                    print()\n",
    "                # The section to generate the relation\n",
    "                temp = {}\n",
    "                for ls in global_path:\n",
    "                    for item in ls[:-1]:\n",
    "                        if item.key in temp:\n",
    "                            temp[item.key] += ls[-1].count\n",
    "                        else:\n",
    "                            temp[item.key] = ls[-1].count\n",
    "                # Generate the conditional pattern base\n",
    "                root = Node('r')\n",
    "                t = None\n",
    "                for ls in global_path:\n",
    "                    r = root\n",
    "                    for item in ls[:-1]:\n",
    "                        if temp[item.key] >= self.min_sup and not r.contain_with(item.key):\n",
    "                            t = Node(item.key)\n",
    "                            t.count = (ls[-1].count -1)\n",
    "                            r = r + t\n",
    "                        elif temp[item.key] >= self.min_sup and r.contain_with(item.key):\n",
    "                            r = (r > item.key)\n",
    "                            r.count = (ls[-1].count)\n",
    "                # Target and pattern base do the combination with the comditional pattern\n",
    "                if root.children == None:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                for key, value in root.children.items():\n",
    "                    ls = []\n",
    "                    self.combination_with_pattern(ls, 0, key, value, global_ls)\n",
    "                    self.combination_with_pattern(ls, 1, key, value, global_ls)\n",
    "                if print_relation:\n",
    "                    for relation in global_ls:\n",
    "                        for item in relation:\n",
    "                            print(f\"({self.le.inverse_transform([item[0]])[0]} {item[1]})\", end=' ')\n",
    "                        print()\n",
    "                    print()\n",
    "                pbar.update(1)\n",
    "\n",
    "    def hash_of_sequence(self,tup):\n",
    "        MAX = 10e21\n",
    "        sum = 1\n",
    "        for i in tup:\n",
    "            i = i+1 if i == 0 else i\n",
    "            sum = sum * i\n",
    "        sum = sum*len(tup)\n",
    "        return sum % MAX\n",
    "    \n",
    "    def gen_fp(self):\n",
    "        # Create a set of frequent pattern\n",
    "        pattern_counts = []\n",
    "        for key, value in self.relations.items():\n",
    "            for relation in value:\n",
    "                tmp = relation.copy()\n",
    "                tmp.append((key, 1))\n",
    "                pattern_counts.append([tuple([item[0] for item in tmp]), relation[-1][1]])\n",
    "        # build dictionary\n",
    "        all_relations = []\n",
    "        for relation in pattern_counts:\n",
    "            all_relations.append(relation[0])\n",
    "        all_relations = frozenset(all_relations)\n",
    "        # Create a dictionary using self.hash_of_sequence\n",
    "        # { hash : (relation)}\n",
    "        relation_dict = {}\n",
    "        len_all_relations = len(all_relations)\n",
    "        for relation in all_relations:\n",
    "            relation_dict[self.hash_of_sequence(relation)] = relation\n",
    "        # Create a dictionary of count using self.hash_of_sequence\n",
    "        # {hash : counts}\n",
    "        count_dict = {}\n",
    "        for relation in pattern_counts:\n",
    "            if hash_of_sequence(relation[0]) in count_dict:\n",
    "                count_dict[hash_of_sequence(relation[0])] += relation[1]\n",
    "            else :\n",
    "                count_dict[hash_of_sequence(relation[0])] = relation[1]\n",
    "        extract_frequent_pattern = []\n",
    "        for key, value in count_dict.items():\n",
    "            if value >= 10:\n",
    "                extract_frequent_pattern.append((key, value))\n",
    "\n",
    "        fp_n = {}\n",
    "        fp_n_encoded = {}\n",
    "        self.Max_fp = 0\n",
    "        for fp in extract_frequent_pattern:\n",
    "            original_pattern = relation_dict[fp[0]]\n",
    "            if len(original_pattern) not in fp_n:\n",
    "                fp_n[len(original_pattern)] = []\n",
    "                fp_n_encoded[len(original_pattern)] = []\n",
    "                if self.Max_fp < len(original_pattern):\n",
    "                    self.Max_fp = len(original_pattern)\n",
    "            t = fp_n[len(original_pattern)]\n",
    "            t_encoded = fp_n_encoded[len(original_pattern)]\n",
    "            t.append( (list(self.le.inverse_transform([p])[0] for p in original_pattern ), fp[1]) )\n",
    "            t_encoded.append( (list(p for p in original_pattern ), fp[1])  )\n",
    "\n",
    "        self.fp_n = fp_n\n",
    "        self.fp_n_encoded = fp_n_encoded\n",
    "        \n",
    "    def support(self, com):\n",
    "        com_s = set(com)\n",
    "        count = 0\n",
    "        for i, row in enumerate(self.encoded_data):\n",
    "            if com_s.issubset(row) :\n",
    "                count += 1\n",
    "        return count/self.dshape[0]\n",
    "\n",
    "    def gen_rule(self, min_conf):\n",
    "        rules = []\n",
    "        for m, m_c in self.fp_n_encoded[self.Max_fp-1]:\n",
    "            for i in range(len(m)-1):\n",
    "                for com in itertools.combinations(m, i+1):\n",
    "                    sm = self.support(m)\n",
    "                    scom = self.support(com)\n",
    "                    if sm/scom >= min_conf:\n",
    "                        rules.append({'rule': [com, tuple(set(m).difference(com))], 'confidence': sm/scom, 'support': sm})\n",
    "        return rules\n",
    "    def print_out_rules(self, rules):\n",
    "        for dr in rules:\n",
    "            print(f\"{self.le.inverse_transform(dr['rule'][0])} => {self.le.inverse_transform(dr['rule'][1])}, with confidence {dr['confidence']} and support {dr['support']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame([['a','c','d','f','g','i','m','p'], ['a','b','c','f','i','m','o'], ['b','f', 'h', 'j','o'],['b','c','k','s','p'], ['a','c','e','f','l','m','n','p'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(data_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpe = FPEstimator(data_df[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpe.encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpe.l1label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpe.build_tree(10, print_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x7fa41778d080>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpe.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in fpe.ht:\n",
    "#     cur = d['next']\n",
    "#     while cur != None:\n",
    "#         print(cur.key, cur.count)\n",
    "#         cur = cur.next_instance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 79/80 [00:03<00:00, 21.18it/s]\n"
     ]
    }
   ],
   "source": [
    "fpe.gen_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 83.11it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('fp-relation_test', 'w')\n",
    "with tqdm(total = len(fpe.relations.keys())) as pbar:\n",
    "    for key, value in fpe.relations.items():\n",
    "        f.write(f\"=================================\\n\")\n",
    "        f.write(f\"Find ({key} {fpe.le.inverse_transform([key])[0]})\\n\")\n",
    "        for relation in value:\n",
    "            for item in relation:\n",
    "                f.write(f\"({fpe.le.inverse_transform([item[0]])[0]} {item[1]}) \")\n",
    "            f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpe.gen_fp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [(['spaghetti', 'french wine'], 10),\n",
       "  (['spaghetti', 'ham'], 13),\n",
       "  (['chocolate', 'rice'], 10),\n",
       "  (['mineral water', 'rice'], 11),\n",
       "  (['mineral water', 'protein bar'], 10),\n",
       "  (['french fries', 'strawberries'], 10),\n",
       "  (['mineral water', 'fresh tuna'], 13),\n",
       "  (['shrimp', 'pasta'], 21),\n",
       "  (['burgers', 'almonds'], 10),\n",
       "  (['milk', 'almonds'], 10),\n",
       "  (['eggs', 'almonds'], 19),\n",
       "  (['mineral water', 'almonds'], 39),\n",
       "  (['green tea', 'cookies'], 17),\n",
       "  (['milk', 'tomatoes'], 16),\n",
       "  (['eggs', 'tomatoes'], 29),\n",
       "  (['chocolate', 'yams'], 10),\n",
       "  (['mineral water', 'yams'], 14),\n",
       "  (['chocolate', 'pepper'], 12),\n",
       "  (['spaghetti', 'pepper'], 11),\n",
       "  (['eggs', 'pepper'], 20),\n",
       "  (['mineral water', 'pepper'], 40),\n",
       "  (['spaghetti', 'hot dogs'], 10),\n",
       "  (['eggs', 'red wine'], 10),\n",
       "  (['mineral water', 'red wine'], 14),\n",
       "  (['milk', 'avocado'], 14),\n",
       "  (['chocolate', 'avocado'], 10),\n",
       "  (['mineral water', 'avocado'], 28),\n",
       "  (['spaghetti', 'tomatoes'], 32),\n",
       "  (['milk', 'fresh bread'], 10),\n",
       "  (['french fries', 'fresh bread'], 13),\n",
       "  (['chocolate', 'fresh bread'], 14),\n",
       "  (['eggs', 'fresh bread'], 20),\n",
       "  (['mineral water', 'fresh bread'], 66),\n",
       "  (['olive oil', 'whole wheat pasta'], 15),\n",
       "  (['ground beef', 'whole wheat pasta'], 10),\n",
       "  (['spaghetti', 'whole wheat pasta'], 20),\n",
       "  (['mineral water', 'whole wheat pasta'], 60),\n",
       "  (['green tea', 'butter'], 10),\n",
       "  (['milk', 'butter'], 10),\n",
       "  (['french fries', 'butter'], 18),\n",
       "  (['chocolate', 'butter'], 39),\n",
       "  (['frozen vegetables', 'tomatoes'], 12),\n",
       "  (['mineral water', 'tomatoes'], 52),\n",
       "  (['mineral water', 'olive oil'], 646),\n",
       "  (['shrimp', 'salmon'], 10),\n",
       "  (['milk', 'salmon'], 10),\n",
       "  (['spaghetti', 'salmon'], 22),\n",
       "  (['mineral water', 'salmon'], 57),\n",
       "  (['spaghetti', 'tomato juice'], 11),\n",
       "  (['eggs', 'tomato juice'], 21),\n",
       "  (['pancakes', 'tomato juice'], 10),\n",
       "  (['mineral water', 'tomato juice'], 39),\n",
       "  (['frozen vegetables', 'honey'], 10),\n",
       "  (['spaghetti', 'honey'], 13),\n",
       "  (['spaghetti', 'burgers'], 69),\n",
       "  (['mineral water', 'honey'], 42),\n",
       "  (['french fries', 'champagne'], 12),\n",
       "  (['chocolate', 'champagne'], 15),\n",
       "  (['mineral water', 'champagne'], 20),\n",
       "  (['milk', 'whole wheat rice'], 14),\n",
       "  (['green tea', 'whole wheat rice'], 12),\n",
       "  (['escalope', 'whole wheat rice'], 10),\n",
       "  (['spaghetti', 'whole wheat rice'], 26),\n",
       "  (['chocolate', 'whole wheat rice'], 45),\n",
       "  (['mineral water', 'whole wheat rice'], 160),\n",
       "  (['spaghetti', 'grated cheese'], 16),\n",
       "  (['french fries', 'grated cheese'], 13),\n",
       "  (['chocolate', 'grated cheese'], 18),\n",
       "  (['mineral water', 'grated cheese'], 60),\n",
       "  (['turkey', 'cooking oil'], 10),\n",
       "  (['milk', 'cooking oil'], 13),\n",
       "  (['spaghetti', 'cooking oil'], 18),\n",
       "  (['chocolate', 'cooking oil'], 34),\n",
       "  (['low fat yogurt', 'cooking oil'], 10),\n",
       "  (['eggs', 'cooking oil'], 67),\n",
       "  (['mineral water', 'cooking oil'], 253),\n",
       "  (['shrimp', 'frozen smoothie'], 10),\n",
       "  (['milk', 'frozen smoothie'], 17),\n",
       "  (['green tea', 'frozen smoothie'], 14),\n",
       "  (['spaghetti', 'frozen smoothie'], 45),\n",
       "  (['chocolate', 'frozen smoothie'], 43),\n",
       "  (['french fries', 'frozen smoothie'], 20),\n",
       "  (['eggs', 'frozen smoothie'], 36),\n",
       "  (['mineral water', 'frozen smoothie'], 240),\n",
       "  (['shrimp', 'chicken'], 15),\n",
       "  (['milk', 'chicken'], 12),\n",
       "  (['french fries', 'chicken'], 19),\n",
       "  (['olive oil', 'chicken'], 11),\n",
       "  (['spaghetti', 'chicken'], 70),\n",
       "  (['green tea', 'chicken'], 24),\n",
       "  (['chocolate', 'chicken'], 65),\n",
       "  (['cake', 'chicken'], 10),\n",
       "  (['eggs', 'chicken'], 41),\n",
       "  (['soup', 'chicken'], 11),\n",
       "  (['mineral water', 'chicken'], 368),\n",
       "  (['ground beef', 'herb & pepper'], 19),\n",
       "  (['green tea', 'herb & pepper'], 11),\n",
       "  (['spaghetti', 'herb & pepper'], 36),\n",
       "  (['pancakes', 'herb & pepper'], 10),\n",
       "  (['milk', 'herb & pepper'], 11),\n",
       "  (['chocolate', 'herb & pepper'], 22),\n",
       "  (['eggs', 'herb & pepper'], 150),\n",
       "  (['mineral water', 'herb & pepper'], 338),\n",
       "  (['milk', 'soup'], 36),\n",
       "  (['ground beef', 'soup'], 10),\n",
       "  (['spaghetti', 'soup'], 43),\n",
       "  (['burgers', 'soup'], 10),\n",
       "  (['green tea', 'soup'], 27),\n",
       "  (['olive oil', 'soup'], 15),\n",
       "  (['frozen vegetables', 'soup'], 10),\n",
       "  (['shrimp', 'soup'], 12),\n",
       "  (['chocolate', 'soup'], 92),\n",
       "  (['eggs', 'soup'], 166),\n",
       "  (['mineral water', 'soup'], 558),\n",
       "  (['milk', 'cake'], 21),\n",
       "  (['spaghetti', 'cake'], 27),\n",
       "  (['chocolate', 'cake'], 33),\n",
       "  (['olive oil', 'cake'], 10),\n",
       "  (['burgers', 'cake'], 11),\n",
       "  (['shrimp', 'cake'], 13),\n",
       "  (['turkey', 'cake'], 13),\n",
       "  (['frozen vegetables', 'cake'], 17),\n",
       "  (['pancakes', 'cake'], 11),\n",
       "  (['french fries', 'cake'], 10),\n",
       "  (['eggs', 'cake'], 214),\n",
       "  (['green tea', 'cake'], 16),\n",
       "  (['mineral water', 'cake'], 405),\n",
       "  (['shrimp', 'olive oil'], 12),\n",
       "  (['frozen vegetables', 'olive oil'], 13),\n",
       "  (['ground beef', 'olive oil'], 14),\n",
       "  (['milk', 'olive oil'], 29),\n",
       "  (['french fries', 'olive oil'], 16),\n",
       "  (['spaghetti', 'olive oil'], 81),\n",
       "  (['chocolate', 'olive oil'], 87),\n",
       "  (['eggs', 'olive oil'], 70),\n",
       "  (['pancakes', 'olive oil'], 12),\n",
       "  (['french fries', 'cookies'], 16),\n",
       "  (['eggs', 'cookies'], 12),\n",
       "  (['chocolate', 'cookies'], 24),\n",
       "  (['burgers', 'turkey'], 14),\n",
       "  (['french fries', 'turkey'], 18),\n",
       "  (['spaghetti', 'turkey'], 27),\n",
       "  (['frozen vegetables', 'turkey'], 10),\n",
       "  (['ground beef', 'turkey'], 17),\n",
       "  (['milk', 'turkey'], 16),\n",
       "  (['chocolate', 'turkey'], 38),\n",
       "  (['eggs', 'turkey'], 375),\n",
       "  (['green tea', 'turkey'], 16),\n",
       "  (['mineral water', 'turkey'], 231),\n",
       "  (['green tea', 'burgers'], 30),\n",
       "  (['french fries', 'burgers'], 29),\n",
       "  (['ground beef', 'burgers'], 12),\n",
       "  (['pancakes', 'burgers'], 14),\n",
       "  (['milk', 'burgers'], 21),\n",
       "  (['chocolate', 'burgers'], 52),\n",
       "  (['eggs', 'burgers'], 306),\n",
       "  (['shrimp', 'burgers'], 11),\n",
       "  (['mineral water', 'burgers'], 408),\n",
       "  (['milk', 'escalope'], 11),\n",
       "  (['spaghetti', 'escalope'], 25),\n",
       "  (['french fries', 'escalope'], 16),\n",
       "  (['chocolate', 'escalope'], 20),\n",
       "  (['eggs', 'escalope'], 20),\n",
       "  (['mineral water', 'escalope'], 110),\n",
       "  (['spaghetti', 'low fat yogurt'], 15),\n",
       "  (['chocolate', 'low fat yogurt'], 21),\n",
       "  (['pancakes', 'low fat yogurt'], 11),\n",
       "  (['french fries', 'low fat yogurt'], 18),\n",
       "  (['eggs', 'low fat yogurt'], 60),\n",
       "  (['mineral water', 'low fat yogurt'], 189),\n",
       "  (['green tea', 'shrimp'], 13),\n",
       "  (['french fries', 'shrimp'], 17),\n",
       "  (['spaghetti', 'shrimp'], 41),\n",
       "  (['milk', 'shrimp'], 21),\n",
       "  (['frozen vegetables', 'shrimp'], 14),\n",
       "  (['chocolate', 'shrimp'], 67),\n",
       "  (['eggs', 'shrimp'], 138),\n",
       "  (['mineral water', 'shrimp'], 390),\n",
       "  (['green tea', 'pancakes'], 22),\n",
       "  (['french fries', 'pancakes'], 29),\n",
       "  (['ground beef', 'pancakes'], 14),\n",
       "  (['milk', 'pancakes'], 15),\n",
       "  (['spaghetti', 'pancakes'], 68),\n",
       "  (['chocolate', 'pancakes'], 46),\n",
       "  (['eggs', 'pancakes'], 203),\n",
       "  (['mineral water', 'pancakes'], 416),\n",
       "  (['green tea', 'frozen vegetables'], 16),\n",
       "  (['ground beef', 'frozen vegetables'], 19),\n",
       "  (['french fries', 'frozen vegetables'], 22),\n",
       "  (['milk', 'frozen vegetables'], 22),\n",
       "  (['spaghetti', 'frozen vegetables'], 111),\n",
       "  (['chocolate', 'frozen vegetables'], 67),\n",
       "  (['eggs', 'frozen vegetables'], 126),\n",
       "  (['mineral water', 'frozen vegetables'], 385),\n",
       "  (['milk', 'ground beef'], 25),\n",
       "  (['spaghetti', 'ground beef'], 56),\n",
       "  (['green tea', 'ground beef'], 12),\n",
       "  (['chocolate', 'ground beef'], 67),\n",
       "  (['french fries', 'ground beef'], 10),\n",
       "  (['eggs', 'ground beef'], 128),\n",
       "  (['mineral water', 'ground beef'], 370),\n",
       "  (['green tea', 'milk'], 23),\n",
       "  (['spaghetti', 'milk'], 63),\n",
       "  (['french fries', 'milk'], 25),\n",
       "  (['chocolate', 'milk'], 120),\n",
       "  (['eggs', 'milk'], 194),\n",
       "  (['mineral water', 'milk'], 470),\n",
       "  (['spaghetti', 'green tea'], 24),\n",
       "  (['french fries', 'green tea'], 29),\n",
       "  (['chocolate', 'green tea'], 31),\n",
       "  (['eggs', 'green tea'], 83),\n",
       "  (['mineral water', 'green tea'], 204),\n",
       "  (['spaghetti', 'french fries'], 32),\n",
       "  (['chocolate', 'french fries'], 37),\n",
       "  (['eggs', 'french fries'], 80),\n",
       "  (['mineral water', 'french fries'], 108),\n",
       "  (['chocolate', 'spaghetti'], 50),\n",
       "  (['eggs', 'spaghetti'], 38),\n",
       "  (['mineral water', 'spaghetti'], 116),\n",
       "  (['eggs', 'chocolate'], 42),\n",
       "  (['mineral water', 'chocolate'], 59),\n",
       "  (['mineral water', 'eggs'], 60)],\n",
       " 3: [(['spaghetti', 'green tea', 'burgers'], 11),\n",
       "  (['green tea', 'frozen vegetables', 'tomatoes'], 15),\n",
       "  (['mineral water', 'spaghetti', 'olive oil'], 37),\n",
       "  (['mineral water', 'milk', 'olive oil'], 23),\n",
       "  (['mineral water', 'eggs', 'olive oil'], 19),\n",
       "  (['mineral water', 'spaghetti', 'burgers'], 20),\n",
       "  (['chocolate', 'spaghetti', 'whole wheat rice'], 12),\n",
       "  (['mineral water', 'chocolate', 'whole wheat rice'], 21),\n",
       "  (['eggs', 'chocolate', 'cooking oil'], 10),\n",
       "  (['mineral water', 'chocolate', 'cooking oil'], 12),\n",
       "  (['mineral water', 'eggs', 'cooking oil'], 55),\n",
       "  (['mineral water', 'eggs', 'frozen smoothie'], 18),\n",
       "  (['mineral water', 'french fries', 'chicken'], 10),\n",
       "  (['mineral water', 'spaghetti', 'chicken'], 21),\n",
       "  (['mineral water', 'chocolate', 'chicken'], 37),\n",
       "  (['mineral water', 'eggs', 'chicken'], 20),\n",
       "  (['eggs', 'spaghetti', 'herb & pepper'], 11),\n",
       "  (['mineral water', 'spaghetti', 'herb & pepper'], 14),\n",
       "  (['mineral water', 'chocolate', 'herb & pepper'], 10),\n",
       "  (['mineral water', 'eggs', 'herb & pepper'], 60),\n",
       "  (['chocolate', 'milk', 'soup'], 19),\n",
       "  (['eggs', 'milk', 'soup'], 15),\n",
       "  (['eggs', 'chocolate', 'soup'], 20),\n",
       "  (['mineral water', 'olive oil', 'soup'], 11),\n",
       "  (['mineral water', 'milk', 'soup'], 16),\n",
       "  (['mineral water', 'spaghetti', 'soup'], 31),\n",
       "  (['mineral water', 'chocolate', 'soup'], 64),\n",
       "  (['mineral water', 'eggs', 'soup'], 12),\n",
       "  (['eggs', 'spaghetti', 'cake'], 11),\n",
       "  (['eggs', 'chocolate', 'cake'], 11),\n",
       "  (['mineral water', 'spaghetti', 'cake'], 11),\n",
       "  (['mineral water', 'shrimp', 'cake'], 12),\n",
       "  (['mineral water', 'eggs', 'cake'], 54),\n",
       "  (['spaghetti', 'milk', 'olive oil'], 17),\n",
       "  (['chocolate', 'milk', 'olive oil'], 10),\n",
       "  (['chocolate', 'spaghetti', 'olive oil'], 22),\n",
       "  (['mineral water', 'chocolate', 'olive oil'], 41),\n",
       "  (['eggs', 'spaghetti', 'turkey'], 12),\n",
       "  (['eggs', 'chocolate', 'turkey'], 21),\n",
       "  (['mineral water', 'eggs', 'turkey'], 50),\n",
       "  (['eggs', 'spaghetti', 'burgers'], 15),\n",
       "  (['eggs', 'chocolate', 'burgers'], 24),\n",
       "  (['french fries', 'milk', 'burgers'], 10),\n",
       "  (['mineral water', 'milk', 'burgers'], 10),\n",
       "  (['mineral water', 'chocolate', 'burgers'], 13),\n",
       "  (['mineral water', 'eggs', 'burgers'], 117),\n",
       "  (['mineral water', 'spaghetti', 'escalope'], 11),\n",
       "  (['mineral water', 'eggs', 'escalope'], 12),\n",
       "  (['mineral water', 'spaghetti', 'low fat yogurt'], 12),\n",
       "  (['mineral water', 'eggs', 'low fat yogurt'], 24),\n",
       "  (['eggs', 'chocolate', 'shrimp'], 17),\n",
       "  (['mineral water', 'milk', 'shrimp'], 10),\n",
       "  (['mineral water', 'chocolate', 'shrimp'], 29),\n",
       "  (['mineral water', 'eggs', 'shrimp'], 60),\n",
       "  (['chocolate', 'spaghetti', 'pancakes'], 13),\n",
       "  (['eggs', 'spaghetti', 'pancakes'], 22),\n",
       "  (['eggs', 'chocolate', 'pancakes'], 20),\n",
       "  (['mineral water', 'spaghetti', 'pancakes'], 28),\n",
       "  (['mineral water', 'chocolate', 'pancakes'], 28),\n",
       "  (['mineral water', 'eggs', 'pancakes'], 50),\n",
       "  (['spaghetti', 'french fries', 'frozen vegetables'], 11),\n",
       "  (['spaghetti', 'milk', 'frozen vegetables'], 10),\n",
       "  (['chocolate', 'milk', 'frozen vegetables'], 13),\n",
       "  (['chocolate', 'spaghetti', 'frozen vegetables'], 25),\n",
       "  (['eggs', 'french fries', 'frozen vegetables'], 10),\n",
       "  (['eggs', 'chocolate', 'frozen vegetables'], 17),\n",
       "  (['mineral water', 'milk', 'frozen vegetables'], 11),\n",
       "  (['mineral water', 'spaghetti', 'frozen vegetables'], 17),\n",
       "  (['mineral water', 'ground beef', 'frozen vegetables'], 10),\n",
       "  (['mineral water', 'chocolate', 'frozen vegetables'], 23),\n",
       "  (['mineral water', 'eggs', 'frozen vegetables'], 24),\n",
       "  (['chocolate', 'spaghetti', 'ground beef'], 12),\n",
       "  (['eggs', 'spaghetti', 'ground beef'], 14),\n",
       "  (['eggs', 'chocolate', 'ground beef'], 16),\n",
       "  (['mineral water', 'milk', 'ground beef'], 12),\n",
       "  (['mineral water', 'spaghetti', 'ground beef'], 15),\n",
       "  (['mineral water', 'chocolate', 'ground beef'], 38),\n",
       "  (['mineral water', 'eggs', 'ground beef'], 32),\n",
       "  (['chocolate', 'french fries', 'milk'], 10),\n",
       "  (['chocolate', 'spaghetti', 'milk'], 21),\n",
       "  (['eggs', 'french fries', 'milk'], 11),\n",
       "  (['eggs', 'spaghetti', 'milk'], 14),\n",
       "  (['eggs', 'chocolate', 'milk'], 48),\n",
       "  (['mineral water', 'spaghetti', 'milk'], 22),\n",
       "  (['mineral water', 'chocolate', 'milk'], 54),\n",
       "  (['mineral water', 'eggs', 'milk'], 80),\n",
       "  (['mineral water', 'chocolate', 'green tea'], 20),\n",
       "  (['mineral water', 'eggs', 'green tea'], 14),\n",
       "  (['chocolate', 'spaghetti', 'french fries'], 13),\n",
       "  (['mineral water', 'spaghetti', 'french fries'], 10),\n",
       "  (['mineral water', 'chocolate', 'french fries'], 11),\n",
       "  (['mineral water', 'eggs', 'french fries'], 18),\n",
       "  (['eggs', 'chocolate', 'spaghetti'], 13),\n",
       "  (['mineral water', 'chocolate', 'spaghetti'], 16),\n",
       "  (['mineral water', 'eggs', 'spaghetti'], 17),\n",
       "  (['mineral water', 'eggs', 'chocolate'], 14)],\n",
       " 4: [(['mineral water', 'spaghetti', 'milk', 'olive oil'], 15),\n",
       "  (['eggs', 'chocolate', 'milk', 'soup'], 11),\n",
       "  (['mineral water', 'chocolate', 'spaghetti', 'olive oil'], 10),\n",
       "  (['eggs', 'chocolate', 'spaghetti', 'milk'], 10),\n",
       "  (['mineral water', 'chocolate', 'spaghetti', 'milk'], 11),\n",
       "  (['mineral water', 'eggs', 'chocolate', 'milk'], 18)]}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpe.fp_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['green tea' 'tomatoes'] => ['frozen vegetables'], with confidence 0.5 and support 0.005\n",
      "['milk' 'olive oil'] => ['mineral water'], with confidence 0.5789473684210527 and support 0.011\n",
      "['spaghetti' 'whole wheat rice'] => ['chocolate'], with confidence 0.5 and support 0.007\n",
      "['eggs' 'cooking oil'] => ['mineral water'], with confidence 0.7333333333333333 and support 0.011\n",
      "['eggs' 'frozen smoothie'] => ['mineral water'], with confidence 0.5 and support 0.006\n",
      "['chocolate' 'chicken'] => ['mineral water'], with confidence 0.5 and support 0.007\n",
      "['chocolate' 'soup'] => ['milk'], with confidence 0.5 and support 0.01\n",
      "['eggs' 'soup'] => ['milk'], with confidence 0.5 and support 0.009\n",
      "['olive oil' 'soup'] => ['mineral water'], with confidence 0.7333333333333333 and support 0.011\n",
      "['spaghetti' 'soup'] => ['mineral water'], with confidence 0.5882352941176471 and support 0.01\n",
      "['chocolate' 'soup'] => ['mineral water'], with confidence 0.6 and support 0.012\n",
      "['shrimp' 'cake'] => ['mineral water'], with confidence 0.8999999999999999 and support 0.009\n",
      "['chocolate' 'burgers'] => ['eggs'], with confidence 0.5 and support 0.008\n",
      "['french fries' 'burgers'] => ['milk'], with confidence 0.5263157894736842 and support 0.01\n",
      "['mineral water' 'burgers'] => ['eggs'], with confidence 0.5416666666666666 and support 0.013\n",
      "['mineral water' 'escalope'] => ['spaghetti'], with confidence 0.5 and support 0.011\n",
      "['spaghetti' 'escalope'] => ['mineral water'], with confidence 0.5789473684210527 and support 0.011\n",
      "['spaghetti' 'low fat yogurt'] => ['mineral water'], with confidence 0.7 and support 0.007\n",
      "['chocolate' 'pancakes'] => ['spaghetti'], with confidence 0.5 and support 0.008\n",
      "['chocolate' 'pancakes'] => ['eggs'], with confidence 0.5 and support 0.008\n",
      "['chocolate' 'pancakes'] => ['mineral water'], with confidence 0.5625 and support 0.009\n",
      "['french fries' 'frozen vegetables'] => ['spaghetti'], with confidence 0.5 and support 0.007\n",
      "['chocolate' 'frozen vegetables'] => ['milk'], with confidence 0.5652173913043478 and support 0.013\n",
      "['milk' 'frozen vegetables'] => ['chocolate'], with confidence 0.5909090909090909 and support 0.013\n",
      "['milk' 'frozen vegetables'] => ['mineral water'], with confidence 0.5 and support 0.011\n",
      "['ground beef' 'frozen vegetables'] => ['mineral water'], with confidence 0.5263157894736842 and support 0.01\n",
      "['chocolate' 'green tea'] => ['mineral water'], with confidence 0.5 and support 0.011\n"
     ]
    }
   ],
   "source": [
    "rules = fpe.gen_rule(0.5)\n",
    "fpe.print_out_rules(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
